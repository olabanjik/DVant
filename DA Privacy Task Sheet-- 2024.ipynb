{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f59e3e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "On the following pages is an exercise to give you a flavor of topics which will concern you as a Privacy Hub data analyst. Your answers will show us something of the way you work and think as well as how well you communicate. When in doubt about how to proceed, please use your best judgment. We do require that your answers are entirely your own work and that you cite where any external resources are used.\n",
    "\n",
    "Your answers should include the code used to produce your findings. Where you describe your findings, do so in a non-technical way, being careful with wording. The reader should not need to execute your code to see your answers.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd48eac",
   "metadata": {},
   "source": [
    "## Technical Instructions\n",
    "\n",
    "The remainder of this notebook is divided into 2 sections. Section 1 consists of questions for you to answer directly in the notebook. Your submission should consist of an html or pdf export of this notebook. Send your results by attaching them in an email to the address that you received this exercise from.\n",
    "\n",
    "Section 2 consists of an appendix that will be referenced in Section 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc6288",
   "metadata": {},
   "source": [
    "### Personal Hobbies\n",
    "\n",
    "The following questions involve working with the dataset that was sent with this notebook. This is toy data which has been created within Privacy Hub and does not reflect any real people. The dataset includes a number of variables relating to physical attributes, hobbies and a ‘token’ which is used to distinguish one patient from another. A token is a value which is created from any one or more input values. It looks nonsensical (as it is a ‘hash’) and cannot be re-engineered to the original value. An example is provided alongside a more detailed explanation in the Appendix.\n",
    "\n",
    "This data has been sent to you from a prospective client who intends to use the data for some analyses on inferring hobby trends across different demographics. The client has informed you that the tokens are created using data within the dataset itself, which is encrypted using a robust and trusted algorithm.\n",
    "\n",
    "For the following questions, where appropriate, use code and language that is concise, efficient, easy-to-read and annotated to explain what’s going on. Where a question is open-ended, it is encouraged that you are succinct in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec4342",
   "metadata": {},
   "source": [
    "a) Using the dataset and information above, determine which variables have been used to create the token. Can you comment on how this token might be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de06dad-e37a-4205-9ff8-200fe4e1ecda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panda\n",
      "  Downloading panda-0.3.1.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from panda) (68.0.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from panda) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->panda) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->panda) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->panda) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->panda) (2023.11.17)\n",
      "Building wheels for collected packages: panda\n",
      "  Building wheel for panda (setup.py): started\n",
      "  Building wheel for panda (setup.py): finished with status 'done'\n",
      "  Created wheel for panda: filename=panda-0.3.1-py3-none-any.whl size=7245 sha256=687cc0b053dc831500f369ffe82a7afd1479c7dd6aa201c0e3ba8e8f10db80cc\n",
      "  Stored in directory: c:\\users\\my pc\\appdata\\local\\pip\\cache\\wheels\\df\\5c\\39\\36f8dae25a1e88d6ec4411dec4a143781e64fdff6897758eec\n",
      "Successfully built panda\n",
      "Installing collected packages: panda\n",
      "Successfully installed panda-0.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cad45f3-0c3b-458a-b8b6-6e0017a6e1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - numpy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.12.12 |       haa95532_0         127 KB\n",
      "    certifi-2023.11.17         |  py311haa95532_0         160 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         286 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.11.~ --> pkgs/main::ca-certificates-2023.12.12-haa95532_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2023.11.1~ --> pkgs/main/win-64::certifi-2023.11.17-py311haa95532_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2023.11.17   | 160 KB    |            |   0% \n",
      "\n",
      "ca-certificates-2023 | 127 KB    |            |   0% \u001b[A\n",
      "\n",
      "ca-certificates-2023 | 127 KB    | #2         |  13% \u001b[A\n",
      "certifi-2023.11.17   | 160 KB    | #          |  10% \n",
      "\n",
      "ca-certificates-2023 | 127 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "ca-certificates-2023 | 127 KB    | ########## | 100% \u001b[A\n",
      "certifi-2023.11.17   | 160 KB    | ########## | 100% \n",
      "certifi-2023.11.17   | 160 KB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.11.0\n",
      "\n",
      "\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/ca-certificates-2023.12.12-haa95532_0.conda HTTP/1.1\" 200 129785\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/certifi-2023.11.17-py311haa95532_0.conda HTTP/1.1\" 200 163512\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72790b37",
   "metadata": {},
   "source": [
    "b) Calculate the average weight for a person with blue eyes aged between 20 and 50 (inclusive). (Assume every row represents a unique individual)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01858005",
   "metadata": {},
   "source": [
    "c) Comment on the distribution of values within the height column, can you explain why there may be such a wide range of values? (hint: it may be useful to research real height distributions in the human population)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7a72",
   "metadata": {},
   "source": [
    "d) Notice that row 12 (incl. header) begins to shift columns to the left and leads to misalignment. Further queries reveal that this is an error due to missing age information during manual data entry. Given the format of the file, can you identify a simple fix to ensure this misalignment doesn’t happen and formatting remains consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ea419",
   "metadata": {},
   "source": [
    "e) The client wishes to use the dataset partly to analyze the relationship between sex and favorite hobby. Comment on any pre-processing steps you think are necessary before performing such analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebe49e",
   "metadata": {},
   "source": [
    "f) Upon further conversation, the client reveals to you that the dataset provided is a sample of a larger dataset, which consists of 100,000 unique individuals.\n",
    "\n",
    "    i) Comment on the validity of using this data sample to draw any statistical conclusions about the entire dataset  \n",
    "    ii) What advice would you give the client should they ask how best to prepare a data sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde9cbf-1aa9-4211-b912-4380683d8e8d",
   "metadata": {},
   "source": [
    "g) Part of our work at Privacy Hub invovles applying industry-standard guidance to various real life use cases. Such guidance often takes the form of modifications to a dataset in the name of reducing risk of re-identification. Briefly describe how you would implement the following modifications.\n",
    "\n",
    "    i) Height must be capped at 183cm for females and 198cm for males.\n",
    "    ii) All marital status values present must be limited to one of: \"Married\", \"Single\", \"Divorced\", \"Widowed\", or \"Unknown\". Furthermore, marital status must not be present for patients under 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fb273",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "\n",
    "To illustrate the tokenisation process, consider the data found in the table below. To create the associated tokens, the variables var1 and var2 have been fed into a tokenization engine. Thus, rows with the same entries in both these variables have the same tokens, despite potentially representing different individuals (this is known as token colliding (or clashing)).\n",
    "\n",
    "| var1 | var2 | token     |\n",
    "|------|------|-----------|\n",
    "| A    | X    | 2fw4hcl7  |\n",
    "| A    | Y    | oa3t6saj  |\n",
    "| B    | X    | a56plm9   |\n",
    "| A    | X    | 2fw4hcl7  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
